# Titanic Survival Prediction ðŸš¢ | Machine Learning Project

## ðŸ“‹ Task Objectives
- Develop a machine learning model to predict whether a passenger survived the Titanic disaster.
- Handle missing values, encode categorical variables, and normalize numerical data properly.
- Evaluate model performance using metrics like **accuracy**, **precision**, **recall**, and **F1-score**.
- Compare multiple classification models and select the best-performing one.

---

## ðŸ›  Steps to Run the Project

1. **Clone the Repository**
   ```bash
   git clone https://github.com/your-username/titanic-survival-prediction.git
   cd titanic-survival-prediction
   ```

2. **Install Required Packages**
   ```bash
   pip install -r requirements.txt
   ```
   *(Packages include pandas, numpy, scikit-learn, matplotlib, seaborn)*

3. **Prepare the Dataset**
   - Place the dataset file (`tested.csv`) in the project directory.
   
4. **Run the Notebook**
   - Open `Titanic_Survival_Prediction.ipynb` using Jupyter Notebook or any compatible IDE.
   - Follow through the notebook for:
     - Data Cleaning
     - Preprocessing
     - Model Training
     - Evaluation and Results

---

## ðŸ§¹ Project Structure

```
titanic-survival-prediction/
â”‚
â”œâ”€â”€ Titanic_Survival_Prediction.ipynb  # Main notebook
â”œâ”€â”€ tested.csv                         # Dataset
â”œâ”€â”€ README.md                           # Project documentation
â”œâ”€â”€ requirements.txt                   # Python dependencies
```

---

## ðŸ“ˆ Models Implemented
- Logistic Regression
- Decision Tree Classifier
- K-Nearest Neighbors (KNN)
- Naive Bayes Classifier
- Random Forest Classifier
- Support Vector Machine (SVM)
- Kernel SVM (RBF)

Each model is evaluated based on:
- Accuracy
- Precision
- Recall
- F1-Score

A final comparison table summarizes the performance of all models.

---

## ðŸ† Results
- The project successfully predicts survival with **strong accuracy**.
- Metrics such as precision, recall, and F1-Score were carefully analyzed for deeper evaluation beyond accuracy alone.

---

## ðŸ§  Innovation and Creativity
- Compared **seven different models** systematically.
- Performed **feature encoding**, **missing value imputation**, and **scaling** for robust preprocessing.
---

## ðŸ“š Documentation and Code Quality
- Code is **modular**, **well-commented**, and **easy to follow**.
- Preprocessing, training, and evaluation are clearly separated.
- All steps are reproducible through the provided notebook.

---

> **Maintained by:** Niharika Barnwal
> **GitHub:** [NiharikaBarnwal](https://github.com/NiharikaBarnwal)

